"improved_loop:\n\t"
    "vsetvli t0, %[arr_size], e16\n\t"
    
    "vle16.v v0, (%[h])\n\t"
    "sub %[arr_size], %[arr_size], t0\n\t"
    "slli t0, t0, 1\n\t"
    "add %[h], %[h], t0\n\t"
    "vle16.v v1, (%[x])\n\t"
    "add %[x], %[x], t0\n\t"
    "vmv.v.x v2, %[id]\n\t"
    "vmul.vv v0, v0, v1\n\t"
    "vadd.vv v0, v2, v0\n\t"   
    "vse16.v v0, (%[y])\n\t"
    "add %[y], %[y], t0\n\t"
    
    "addi %[add_cnt], %[add_cnt], 4\n\t"
    "addi %[sub_cnt], %[sub_cnt], 1\n\t"
    "addi %[mul_cnt], %[mul_cnt], 1\n\t"
    "addi %[div_cnt], %[div_cnt], 0\n\t"
    "addi %[lw_cnt], %[lw_cnt], 2\n\t"
    "addi %[sw_cnt], %[sw_cnt], 1\n\t"
    "addi %[others_cnt], %[others_cnt], 4\n\t"
    
    "bnez %[arr_size], improved_loop\n\t"
